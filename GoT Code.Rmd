---
title: 'Game of Thrones: IMDb Scraping and Analysis'
author: "Patricia Tang"
date: "5/20/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Part 1: Scraping the Data

``` {r}
library(xml2)
library(rvest)
library(tm)
library(SnowballC)
library(broom)
library(tidytext)
library(ggplot2)
library(lubridate)
library(dplyr)
```

``` {r}
# from Napon - GENERAL information about episodes. no keywords, no directors, etc. 
get_info <- function(x){
  page <- read_html(paste0("https://www.imdb.com/title/tt0944947/episodes?season=",x))
  season <- x
  ep_title <- page %>% html_nodes("#episodes_content strong a") %>% html_text()
  ep_num <- page %>% html_nodes("#episodes_content strong a") %>% html_attr("href") %>% gsub(".*ep", "", .)
  text <- page %>% html_nodes(".item_description") %>% html_text() %>% gsub("\\n ", "", .)
  rating <- page %>% html_nodes(".ipl-rating-star.small .ipl-rating-star__rating") %>% html_text() %>% as.numeric()
  airdate <- page %>% html_nodes(".airdate") %>% html_text() %>% dmy()
  links <- page %>%
  html_nodes("#episodes_content strong a") %>%
  html_attr('href')
  return(data.frame(season, ep_title, ep_num, text, rating, airdate, links, stringsAsFactors = F))
}

Thrones <- lapply(1:8, get_info) %>% bind_rows()
```

``` {r}
# to get full links
for(i in 1:73){
  Thrones$links[i] <- paste("https://www.imdb.com", Thrones$links[i], sep ='')
}
```

``` {r}
# to get href links for keyword scraping
Thrones$keywordlinks <- substr(Thrones$links, start=1, stop=37)
```

``` {r}
# to make full links for all keyword links
for(i in 1:73){
  Thrones$keywordlinks[i] <- paste(Thrones$keywordlinks[i], "keywords?ref_=tt_stry_kw", sep ='') 
  # "keywords?ref_=tt_stry_kw" returns keyword page for ALL IMDb pages here
}
```

``` {r}
# to get keyword data
for(i in 1:73){
  link = as.character(Thrones$keywordlinks[i])
  Thrones$keywords[i] <- read_html(link) %>% html_nodes("div.sodatext") %>%
    html_text %>% paste(collapse = "\n\n")
}
```

``` {r}
# to get directors/writing credits
Thrones$creditlinks <- substr(Thrones$links, start=1, stop=37)
for(i in 1:73){
  Thrones$creditlinks[i] <- paste(Thrones$creditlinks[i], "fullcredits?ref_=tt_ov_wr", sep ='') 
  # "fullcredits?ref_=tt_ov_wr" returns keyword page for ALL IMDb pages here
}
```

``` {r}
# to get credit data
for(i in 1:73){
  link = as.character(Thrones$creditlinks[i])
  Thrones$credits[i] <- read_html(link) %>% html_nodes("#fullcredits_content a") %>%
    html_text %>% paste(collapse = "\n\n")
}
```

``` {r}
# to get directorial credit.
for(i in 1:73){
  link = as.character(Thrones$creditlinks[i])
  Thrones$director[i] <- read_html(link) %>% html_nodes(".simpleCreditsTable:nth-child(2)") %>%
    html_text %>% paste(collapse = "\n\n")
}

```

# Part 2: Prepping for Text Analysis

``` {r}
# DTM for keywords
ThronesCorpus <- VCorpus(VectorSource(Thrones$keywords)) %>% tm_map(removeWords, stopwords("english"))
KeywordDTM = DocumentTermMatrix(ThronesCorpus) 
KeywordDTMclean = KeywordDTM %>% tidy()
```

``` {r}
# DTM for text
TextCorpus <- VCorpus(VectorSource(Thrones$text)) %>% tm_map(removePunctuation) %>% tm_map(tolower) %>% tm_map(removeWords, stopwords("english")) %>% tm_map(PlainTextDocument)
TextDTM = DocumentTermMatrix(TextCorpus) 
TextDTM_copy = TextDTM %>% removeSparseTerms(.99)
TextDTMclean = TextDTM_copy %>% tidy()
tfidf <- TextDTMclean %>%bind_tf_idf(term,document, count)
```

# Part 3: Frequency Analysis

```{r}
# Keywords
Keyword_Matrix <-as.matrix(KeywordDTM)
freq <- sort(colSums(Keyword_Matrix), decreasing = TRUE)
freqdf <-as.data.frame(freq)
top <- head(freq, 20)

top_df <- data.frame(word = names(top), freq = top)
Keywordfreq <- ggplot(data=top_df, aes(x=reorder(word, -freq), y=freq)) + geom_bar(stat="identity") + xlab("Keywords") + ylab("Frequency") + theme(legend.title = element_text(size = 3), legend.text = element_text(size = 0.01), axis.text.x=element_text(angle=45,hjust=1,vjust=0.5)) + ggtitle("Most Frequent Game of Thrones Keywords")
Keywordfreq
```

``` {r}
# Synopsis
TextMatrix <-as.matrix(TextDTM)
freq2 <- sort(colSums(TextMatrix), decreasing = TRUE)
freqdf2 <-as.data.frame(freq2)
top2 <- head(freq2, 20)

top_df2 <- data.frame(word = names(top2), freq = top2)
Textfreq <- ggplot(data=top_df2, aes(x=reorder(word, -freq), y=freq)) + geom_bar(stat="identity") + xlab("Keywords") + ylab("Frequency") + theme(legend.title = element_text(size = 3), legend.text = element_text(size = 0.01), axis.text.x=element_text(angle=45,hjust=1,vjust=0.5)) + ggtitle("Most Frequent Game of Thrones Synopsis Keywords")
Textfreq
```

``` {r}
# Ratings by director 
library(plyr)
library(stringr)
perdirect <- ddply(Thrones, .(director), summarize,  rating=mean(rating))
perdirect$director <- sapply(perdirect$director,
                                    function(x) { gsub("\n", "", x) })
perdirect$director <- sapply(perdirect$director,
                                    function(x) { gsub("[\r\n]", "", x) })
perdirect$director <- sapply(perdirect$director,
                                    function(x) { gsub(" ", "", x) })
perdirect$director <- sapply(perdirect$director,
                                    function(x) {gsub("([[:lower:]])(?=[[:upper:]])", "\\1 ", x, perl = TRUE)})
perdirect
```

``` {r}
Directrat <- ggplot(data=perdirect, aes(x=reorder(director, rating), y=rating)) + geom_bar(stat="identity") + xlab("Director") + ylab("Episode Rating (out of 10)") + theme(legend.title = element_text(size = 3), legend.text = element_text(size = 0.1), axis.text.x=element_text(angle=90,hjust=1,vjust=0.5)) + ggtitle("Episode Rating, By Director(s)") + coord_flip()
Directrat
```

Clearly, we can see that Benioff and Weiss' individually-directed episodes are much lower in quality than those with other uncredited directorial personnel. We also note that episodes with D.B. Weiss credited first (before Benioff) are also slightly higher in rating. 

Neil Marshall, Alex Graves, and Matt Shakman clearly directed the highest-rated episodes. Come back to this later. 

``` {r}
# Scatter plot - episode ratings by director
ruh ruoh
```

``` {r}
Thrones$epnumeral <- c(1:73)
Bestepisodes <- ggplot(data=Thrones, aes(x=epnumeral, y=rating)) + geom_line() + geom_point() + ggtitle("GoT Episode Rating Over Time") + xlab("Episodes") + ylab("Rating") + theme(legend.title = element_text(size = 3), legend.text = element_text(size = 0.01))
Bestepisodes
```

# Part 4: Topic Models

``` {r, results = "hide"}
# Keywords, new VCorpus (stemmed)
library(topicmodels)
library(stm)
KeyCorpus2 <- VCorpus(VectorSource(Thrones$keywords)) %>% tm_map(removePunctuation) %>% tm_map(tolower) %>% tm_map(removeWords, stopwords("english")) %>% tm_map(stemDocument) %>% tm_map(PlainTextDocument)
KeyDTM2 = DocumentTermMatrix(KeyCorpus2) 

out <- stm::readCorpus(KeyDTM2, type = 'slam')
mod.out <- stm(documents = out$documents,
               vocab = out$vocab,
               K = 3, 
               data = Thrones)
summary(mod.out)
```

``` {r, results = "hide"}
# Text, new VCorpus (stemmed)
TextCorpus2 <- VCorpus(VectorSource(Thrones$text)) %>% tm_map(removePunctuation) %>% tm_map(tolower) %>% tm_map(removeWords, stopwords("english")) %>% tm_map(stemDocument) %>% tm_map(PlainTextDocument)
TextDTM2 = DocumentTermMatrix(TextCorpus2) 

out2 <- stm::readCorpus(TextDTM2, type = 'slam')
mod.out2 <- stm(documents = out2$documents,
               vocab = out2$vocab,
               K = 4, 
               data = Thrones)
summary(mod.out2)
```

# Part 5: Regression Analysis

``` {r}
# Creating a dummy for nudity
library(stringr)
Thrones$ND <- ifelse(str_detect(Thrones$keywords, "nudity") == "TRUE", "1", "0") 
Thrones$ND <- as.numeric(Thrones$ND)
```

``` {r}
NDlinear <- lm(Thrones$rating ~ Thrones$ND, data = Thrones)
summary(NDlinear)
```

Relationship between nudity and Game of Thrones episode rating is not statistically significant. 

``` {r}

```